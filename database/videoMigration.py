# https://github.com/mps-youtube/pafy
# https://github.com/r0oth3x49/vimeo
import csv, pafy, datetime, json, io, vimeo_dl

with open( 'import/VeganPlaylist.csv' ) as fh:
    reader = csv.reader( fh )
    data = [ row for row in reader ]

# Organise data into labels and rows
labels = [ label.strip() for label in data[3] ]
data = data[4:]

# Match column values to labels
entries = []
for row in data:
    entry = {}
    tags = []
    for label, value, i in zip( labels, row, range( len( labels ) ) ):
        value = value.strip()
        if label and value:
            if i > 4:
                tags.append( label )
            else:
                entry[label] = value
    if entry and 'URL' in entry:
        entry['tags'] = tags
        entries.append( entry )

strMigrate = """<?php

    /*  !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! *
     *  !! THIS FILE IS AUTOGENERATED !! *
     *  !! YOU SHOULD PROBABLY NOT BE !! *
     *  !!   MANUALLY EDITING THIS.   !! *
     *  !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! */

    use Illuminate\Database\Migrations\Migration;
    use App\Video;

    class ImportVideos extends Migration
    {

        public function up()
        {

            $tags = App\Tag::all();
            $tagId = function( $name ) use ( $tags ) { return $tags->where( 'name', $name )->first()->id; };

            %s
        }

}"""

print 'Processing %d entries...' % len( entries )

# Create migration data string
YtIds = []
ViIds = []
videos = []
for entry in entries:
    if 'vimeo' in entry['URL']:
        try:
            video = vimeo_dl.new( entry['URL'] )
        except KeyboardInterrupt:
            print 'Received keyboard interrupt, exiting'
            exit()
        except:
            print 'Invalid Vimeo URL:', entry['URL']
            continue
        if video.video_id in ViIds:
            print 'Duplicate Vimeo video:', video.video_id
            continue
        ViIds.append( video.video_id )

        res = video.getbest().resolution.split( 'x' )
        videoData = {
            'service': 'v',
            'service_video_id': video.video_id,
            'title': entry['TITLE'] if 'TITLE' in entry else video.title,
            'length': video._info['duration'],
            'widescreen': float( res[0] ) / float( res[1] ) > 1.5,
            'mature': 'Mature' in entry,
            'graphic': 'Graphic' in entry
        }
        entry['views'] = video.viewcounts

    else:
        try:
            video = pafy.new( entry['URL'] )
        except KeyboardInterrupt:
            print 'Received keyboard interrupt, exiting'
            exit()
        except:
            print 'Invalid YouTube URL:', entry['URL']
            continue
        if video.videoid in YtIds:
            print 'Duplicate YouTube video:', video.videoid
            continue
        YtIds.append( video.videoid )

        res = video.getbest().resolution.split( 'x' )
        videoData = {
            'service': 'y',
            'service_video_id': video.videoid,
            'title': entry['TITLE'] if 'TITLE' in entry else video.title,
            'length': video.length,
            'widescreen': float( res[0] ) / float( res[1] ) > 1.5,
            'mature': 'Mature' in entry,
            'graphic': 'Graphic' in entry
        }
        entry['views'] = video.viewcount
    
    entry['data'] = u'$video = App\Video::create( json_decode( \'%s\', true ) );\n' % json.dumps( videoData ).replace( "'", "\\'" )
    for tag in entry['tags']:
        entry['data'] += '$video->tags()->attach( $tagId( "%s" ) );\n' % tag
    entry['data'] += '$video->save();\n'

    videos.append( entry ) # New list, so we omit duplicates


videos.sort( key = lambda v: v['views'], reverse = True )

strData = '\n'.join( [ video[ 'data' ] for video in videos ] )
strData = strData.replace( '\n', '\n' + ' ' * ( 4 * 3 ) )

print 'Processing succesful, %d videos found' % len( videos )

name = datetime.datetime.utcnow().strftime( "migrations/%Y_%m_%d_%H%M%S_import_videos.php")
with io.open( name, 'w', encoding='utf-8') as fh:
    fh.write( strMigrate % strData )
print 'Created migration', name
